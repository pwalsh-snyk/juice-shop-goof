#!/bin/bash

set -e  # Exit on error

# ==================== CONFIGURE HERE ====================
AWS_REGION="us-west-2"
CLUSTER_NAME="juice-shop"
ECR_REPO_NAME="juice-shop-repo"
DEPLOYMENT_YAML="k8s-src/juice-shop-deploy.yaml"
SERVICE_YAML="k8s-src/juice-shop-service.yaml"
NODEGROUP_NAME="juice-shop-arm64-group"
INSTANCE_TYPE="t4g.medium"  # ARM64 instance type
IMAGE_TAG="juice-shop-app"
# ==================== CONFIGURATION END ====================

# âœ… Ensure AWS Credentials Are Set
echo "ðŸ”¹ Checking AWS credentials..."
if ! aws sts get-caller-identity > /dev/null 2>&1; then
    echo "âŒ AWS credentials are invalid or expired. Let's configure them."
    aws configure
fi

# âœ… Verify AWS Credentials Again After Configuration
if ! aws sts get-caller-identity > /dev/null 2>&1; then
    echo "âŒ ERROR: AWS credentials are still invalid. Exiting."
    exit 1
fi
echo "âœ… AWS credentials verified."

# âœ… Check if EKS Cluster exists
echo "ðŸ”¹ Checking if EKS cluster $CLUSTER_NAME exists..."
if eksctl get cluster --name "$CLUSTER_NAME" --region "$AWS_REGION" > /dev/null 2>&1; then
    echo "âœ… EKS cluster $CLUSTER_NAME already exists. Skipping creation."
else
    echo "ðŸš€ Deploying EKS cluster with ARM64 nodes..."
    eksctl create cluster --name "$CLUSTER_NAME" --region "$AWS_REGION" \
      --nodegroup-name "$NODEGROUP_NAME" --node-type "$INSTANCE_TYPE" --nodes 2 --node-ami-family AmazonLinux2
    echo "âœ… EKS cluster deployed successfully."
fi

# âœ… Update kubeconfig so kubectl is authenticated
echo "ðŸ”¹ Updating kubeconfig for kubectl access..."
aws eks update-kubeconfig --region "$AWS_REGION" --name "$CLUSTER_NAME"
echo "âœ… kubeconfig updated. You can now use kubectl."

# âœ… Verify Nodes Are ARM64
echo "ðŸ”¹ Checking node architecture..."
kubectl get nodes -o custom-columns="NAME:.metadata.name,ARCH:.status.nodeInfo.architecture"

# âœ… Get IAM Role for Worker Nodes
echo "ðŸ”¹ Fetching IAM role for worker nodes..."
NODE_ROLE_NAME=$(aws eks describe-nodegroup --cluster-name "$CLUSTER_NAME" --nodegroup-name "$NODEGROUP_NAME" \
  --query "nodegroup.nodeRole" --output text | cut -d'/' -f2 || true)

if [ -z "$NODE_ROLE_NAME" ]; then
    echo "âŒ ERROR: Could not determine the IAM role for worker nodes."
    exit 1
fi

# âœ… Ensure worker nodes have ECR access
echo "ðŸ”¹ Checking IAM policies for worker nodes..."
if ! aws iam list-attached-role-policies --role-name "$NODE_ROLE_NAME" --query "AttachedPolicies[*].PolicyArn" --output text | grep -q "AmazonEC2ContainerRegistryReadOnly"; then
    echo "ðŸš€ Attaching ECR ReadOnly policy to worker node IAM role..."
    aws iam attach-role-policy --role-name "$NODE_ROLE_NAME" --policy-arn arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly
    echo "âœ… ECR ReadOnly policy attached."
else
    echo "âœ… Worker nodes already have ECR ReadOnly policy."
fi

# âœ… Get the Correct ECR Repository URI
echo "ðŸ”¹ Checking ECR repository..."
ECR_URI=$(aws ecr describe-repositories --repository-names "$ECR_REPO_NAME" --region "$AWS_REGION" --query 'repositories[0].repositoryUri' --output text 2>/dev/null || echo "")

if [ -z "$ECR_URI" ]; then
    echo "ðŸš€ Creating ECR repository..."
    ECR_URI=$(aws ecr create-repository --repository-name "$ECR_REPO_NAME" --region "$AWS_REGION" --query 'repository.repositoryUri' --output text)
    echo "âœ… ECR repository created: $ECR_URI"
else
    echo "âœ… ECR repository exists: $ECR_URI"
fi

# âœ… Authenticate Docker with ECR
echo "ðŸ”¹ Logging in to Amazon ECR..."
aws ecr get-login-password --region "$AWS_REGION" | docker login --username AWS --password-stdin "$ECR_URI"
echo "âœ… Docker authenticated with ECR."

# âœ… Build & Push Docker Image
echo "ðŸš€ Building and pushing Juice Shop Docker image..."
docker build -t "$ECR_URI:$IMAGE_TAG" .
docker push "$ECR_URI:$IMAGE_TAG"
echo "âœ… Docker image pushed to ECR."

# âœ… Ensure Kubernetes Deployment Uses Correct Image
echo "ðŸ”¹ Updating Kubernetes manifests..."
if [[ "$OSTYPE" == "darwin"* ]]; then
    sed -i '' "s|<ECR_IMAGE>|$ECR_URI:$IMAGE_TAG|g" "$DEPLOYMENT_YAML"
else
    sed -i "s|<ECR_IMAGE>|$ECR_URI:$IMAGE_TAG|g" "$DEPLOYMENT_YAML"
fi
echo "âœ… Deployment YAML updated."

# âœ… Deploy Juice Shop to EKS
echo "ðŸš€ Deploying Juice Shop to EKS..."
kubectl apply -f "$DEPLOYMENT_YAML"
kubectl apply -f "$SERVICE_YAML"
echo "âœ… Juice Shop application deployed."

# âœ… Restart Deployment to Ensure Correct Image is Used
echo "ðŸ”¹ Restarting deployment to ensure correct image..."
kubectl rollout restart deployment snyk-juice-shop
echo "âœ… Deployment restarted."

# âœ… Verify Pods are Running
echo "ðŸ”¹ Waiting for pods to start..."
kubectl wait --for=condition=ready pod -l app=snyk-juice-shop --timeout=120s || true

# âœ… Get LoadBalancer URL
echo "ðŸ”¹ Fetching LoadBalancer URL..."
sleep 30  # Wait for service to get an external IP
LOAD_BALANCER_URL=$(kubectl get svc juice-shop-service -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || echo "Not ready yet")
echo "âœ… Juice Shop is available at: http://$LOAD_BALANCER_URL"

# âœ… Final Verification
echo "ðŸš€ All done! Run the following command to check pod status:"
echo "kubectl get pods -o wide"


